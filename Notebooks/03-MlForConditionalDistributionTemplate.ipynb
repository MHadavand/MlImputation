{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T03:46:01.126213Z",
     "start_time": "2022-08-28T03:46:01.116713Z"
    }
   },
   "outputs": [],
   "source": [
    "import pygeostat as gs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython\n",
    "from keras_visualizer import visualizer\n",
    "import rmsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T03:46:01.387793Z",
     "start_time": "2022-08-28T03:46:01.383794Z"
    }
   },
   "outputs": [],
   "source": [
    "#TensorFLow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, concatenate\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dropout, GRU, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T03:46:01.665065Z",
     "start_time": "2022-08-28T03:46:01.648532Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('../Tools'))\n",
    "from file_export import PickleExporter, FigureExporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:#1B127A;'>\n",
    "Introduction\n",
    "</h1>\n",
    "\n",
    "This notebook is a template used for creating and training MLP ANN systems that can be trained based on the provided homotopic data and estimate the first four moments of the conditional distribution of a missing variable at a heterotopic data locations. The returned moments can be used to fit a Lambda distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:#1B127A;'>\n",
    "Settings\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:#5177F9;'>\n",
    "Parameter cell\n",
    "</h2>\n",
    "\n",
    "A cell tagged as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T03:46:04.143442Z",
     "start_time": "2022-08-28T03:46:04.135943Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# output of this notebook template\n",
    "outdir = \"Output/MlForConditionalDistCaseStudy/Fe/\"\n",
    "\n",
    "# input directory with pickled data\n",
    "data_dir = \"Output/Imputation_MLP/\"\n",
    "ns_data_pkl = \"data_ns_Fe.pkl\"\n",
    "label_variable = \"Fe\"\n",
    "feature_variables = [\"Ni\", \"SiO2\"]\n",
    "out_file = \"data_out.pkl\"\n",
    "\n",
    "# MLP n_nodes\n",
    "mlp2_nodes_1 = 16\n",
    "mlp2_nodes_2 = 16\n",
    "\n",
    "# File suffix\n",
    "file_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-20T20:05:31.043455Z",
     "start_time": "2022-08-20T20:05:31.038945Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-20T20:05:31.399945Z",
     "start_time": "2022-08-20T20:05:31.389945Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.Parameters['data.tmin'] = -998\n",
    "gs.Parameters['data.null'] = -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:28.879047Z",
     "start_time": "2021-06-14T13:13:28.867050Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_data = PickleExporter(outdir)\n",
    "save_figure = FigureExporter(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:29.144661Z",
     "start_time": "2021-06-14T13:13:29.130668Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_variables = [label_variable]\n",
    "variables = feature_variables + missing_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:#1B127A;'>\n",
    "Load Data\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:29.846918Z",
     "start_time": "2021-06-14T13:13:29.813920Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ns = rmsp.from_pickle(data_dir+ns_data_pkl)\n",
    "data_ns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:#1B127A;'>\n",
    "MLP ANN Design\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:#5177F9;'>\n",
    "Helpers\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:37.187169Z",
     "start_time": "2021-06-14T13:13:32.134911Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.init(\n",
    "    project=f\"NWT_ML_Conditional_Moments_Tuning_{label_variable}\",\n",
    "    entity=\"mosi\",\n",
    "    group=\"NWTCaseStudy\",\n",
    "    tags=[\"Tuning\", 'MLP', 'ConditionalMoments'],\n",
    "    save_code=False\n",
    ")\n",
    "\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "call backs and plot functions\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:37.218862Z",
     "start_time": "2021-06-14T13:13:37.188168Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "try:\n",
    "    from tqdm.keras import TqdmCallback\n",
    "    TqdmCallback = TqdmCallback(verbose=0)\n",
    "except AttributeError:\n",
    "    import tensorflow_addons as tfa\n",
    "    TqdmCallback = tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)\n",
    "\n",
    "def plot_model(history, ax=None, loss_dict=None):\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    if loss_dict is None:\n",
    "        loss_dict = {\"loss\": \"loss\", \"val_loss\": \"val_loss\"}\n",
    "\n",
    "    ax.plot(history.history[loss_dict[\"loss\"]], label=\"Training Loss\", c=\"r\",lw=2)\n",
    "    ax.plot(history.history[loss_dict[\"val_loss\"]], label=\"Validation Loss\", c=\"blue\", ls='--', lw=3)\n",
    "    ax.grid()\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "class LocalCallBacks:\n",
    "    \"\"\"\n",
    "    A class for configuration of ANN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        early_stop_monitor=\"loss\",\n",
    "        min_delta=0.001,\n",
    "        early_stop_patience=200,\n",
    "        lr_reduce_monitor=\"loss\",\n",
    "        lr_reduce_factor=0.1,\n",
    "        lr_reduce_patience=50,\n",
    "        verbose=0,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        # Early stop call back for keras\n",
    "        self.early_stop_clbk = EarlyStopping(\n",
    "            monitor=early_stop_monitor,\n",
    "            min_delta=min_delta,\n",
    "            patience=early_stop_patience,\n",
    "            verbose=0,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        # Adaptive learning rate call back for keras\n",
    "        self.lr_plan = ReduceLROnPlateau(\n",
    "            monitor=lr_reduce_monitor,\n",
    "            factor=lr_reduce_factor,\n",
    "            patience=lr_reduce_patience,\n",
    "            verbose=0,\n",
    "            mode=\"auto\",\n",
    "            min_delta=min_delta,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:18:34.986768Z",
     "start_time": "2021-04-24T21:18:34.968768Z"
    }
   },
   "source": [
    "<h2 style='color:#5177F9;'>\n",
    "Main Configs\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:37.312463Z",
     "start_time": "2021-06-14T13:13:37.298468Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = len(feature_variables)\n",
    "\n",
    "label_variable = missing_variables[0]\n",
    "\n",
    "print('Feature varibale(s):', '\\n'.join(feature_variables))\n",
    "\n",
    "print(f'\\nLabel variable(s): {label_variable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:37.738817Z",
     "start_time": "2021-06-14T13:13:37.714792Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_ns[['Hash'] + feature_variables + [label_variable]].copy()\n",
    "data_train = data_train[data_train.notna().all(axis=1)]\n",
    "\n",
    "data_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Total number of homotopic data: {len(data_train):g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:#5177F9;'>\n",
    "MLP for conditional mean\n",
    "</h2>\n",
    "\n",
    "It is important to have a separate ANN model to get the conditional mean to be able to calculate central moments and control the value using certain activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Data Prep\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:38.676842Z",
     "start_time": "2021-06-14T13:13:38.662850Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X = data_train[feature_variables].values\n",
    "test_X = train_X # Over-fitting is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:38.956319Z",
     "start_time": "2021-06-14T13:13:38.950322Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = data_train[[label_variable]].values.reshape(len(data_train))\n",
    "test_y = train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Model design\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:39.570500Z",
     "start_time": "2021-06-14T13:13:39.453687Z"
    }
   },
   "outputs": [],
   "source": [
    "model_first_moment = Sequential(name=\"FirstMomentMLP\")\n",
    "\n",
    "model_first_moment.add(\n",
    "    Dense(\n",
    "        64,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        input_shape=(n_features,),\n",
    "        name=\"Layer1\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model_first_moment.add(\n",
    "    Dense(\n",
    "        16,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        name=\"Layer2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "model_first_moment.add(\n",
    "    Dense(\n",
    "        4,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        name=\"Layer3\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model_first_moment.add(\n",
    "    Dense(\n",
    "        1,\n",
    "        activation=\"linear\",\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        name=\"output\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "model_first_moment.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Visualize the model\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:40.847181Z",
     "start_time": "2021-06-14T13:13:40.370625Z"
    }
   },
   "outputs": [],
   "source": [
    "visualizer(model_first_moment, format='png', filename=outdir+'model_first_moment')\n",
    "IPython.display.Image (outdir+'model_first_moment.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Configurations\n",
    "</h3>\n",
    "\n",
    "The motivation to use a large batch size (the entire training data set) is that we are assuming the the training data set (sampled data) is representative of the the reference population and using the entire data set we can get a better representation of aleatory uncertainty across feature values.\n",
    "\n",
    "Often, using large batch size can result in regularization gap where the validation accuracy is undermined. This can be due to lower number of updated because there are less updates per epoch. This can be addressed by changing the training regime. For more info read the following paper.\n",
    "\n",
    "*Train longer, generalize better: closing the generalization gap in large batch training of neural networks*, Elad Hoffer and et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:41.739804Z",
     "start_time": "2021-06-14T13:13:41.723805Z"
    }
   },
   "outputs": [],
   "source": [
    "config.batch_size = len(train_X)\n",
    "config.n_epochs = 5000\n",
    "config.initial_learning_rate = 0.01\n",
    "config.loss = 'mse'\n",
    "\n",
    "config.early_stop_monitor = 'loss'\n",
    "config.min_delta = 0.001\n",
    "config.early_stop_patience = 200\n",
    "config.lr_reduce_monitor = 'loss'\n",
    "config.lr_reduce_factor = 0.1\n",
    "config.lr_reduce_patience = 50\n",
    "config.verbose = 0\n",
    "\n",
    "local_clbs = LocalCallBacks(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Compile the model\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:13:42.460240Z",
     "start_time": "2021-06-14T13:13:42.442217Z"
    }
   },
   "outputs": [],
   "source": [
    "model_first_moment.compile(loss=config.loss, \n",
    "              optimizer=Nadam(learning_rate=config.initial_learning_rate), \n",
    "              metrics=[tf.keras.metrics.mean_squared_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Train the model\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:15:35.240109Z",
     "start_time": "2021-06-14T13:13:43.221752Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_first_moment_history = model_first_moment.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs=config.n_epochs,\n",
    "    batch_size=config.batch_size,\n",
    "    validation_data=(test_X, test_y),\n",
    "    callbacks=[\n",
    "        local_clbs.early_stop_clbk,\n",
    "        local_clbs.lr_plan,\n",
    "        WandbCallback(),\n",
    "        TqdmCallback,\n",
    "    ],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Loss vs Epoch plot\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:12.527344Z",
     "start_time": "2021-06-14T13:16:12.410346Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_first_moment_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:#5177F9;'>\n",
    "Set the conditional mean and the central moments (2nd, 3rd and 4th)\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:13.997335Z",
     "start_time": "2021-06-14T13:16:13.870269Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train[label_variable+'_m'] = model_first_moment.predict(data_train[feature_variables].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:14.534882Z",
     "start_time": "2021-06-14T13:16:14.274242Z"
    }
   },
   "outputs": [],
   "source": [
    "label_variables_dev = []\n",
    "for power in (2,3,4):\n",
    "    var = label_variable + f\"deviation_{power}\"\n",
    "    label_variables_dev.append(var)\n",
    "    data_train[var] = data_train[\n",
    "        [label_variable, label_variable + \"_m\"]\n",
    "    ].apply(lambda x: pow((x[0] - x[1]), power), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:#5177F9;'>\n",
    "MLP for 2nd, 3rd and 4th moments\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Data prep\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T05:37:04.733545Z",
     "start_time": "2021-04-25T05:37:04.727574Z"
    }
   },
   "source": [
    "Note: The features remaine the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:15.617293Z",
     "start_time": "2021-06-14T13:16:15.598326Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y_dev = data_train[label_variables_dev].values.reshape(len(data_train), len(label_variables_dev))\n",
    "test_y_dev = train_y_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Model Design\n",
    "</h3>\n",
    "\n",
    "Model network using Keras functional API to have shared and separated layer for each moment so we can train the network to estimate the second, third and first central deviations/moments in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.Input(shape=(len(feature_variables),), name='Input')\n",
    "\n",
    "weight_initilizer = 'glorot_normal' \n",
    "bias_initializer = 'Zeros'\n",
    "\n",
    "\n",
    "layer_shared_1 = Dense(mlp2_nodes_1, activation='relu',\n",
    "                  kernel_initializer=weight_initilizer,\n",
    "                  bias_initializer=bias_initializer,\n",
    "                  name='shared_layer')(input_layer)\n",
    "\n",
    "# Separation layers\n",
    "layer_s_2 = Dense(mlp2_nodes_2*2, activation='relu',\n",
    "                  kernel_initializer=weight_initilizer,\n",
    "                  bias_initializer=bias_initializer,\n",
    "                  name='separation_layer_2')(layer_shared_1)\n",
    "\n",
    "layer_s_3 = Dense(mlp2_nodes_2*2, activation='relu',\n",
    "                  kernel_initializer=weight_initilizer,\n",
    "                  bias_initializer=bias_initializer,\n",
    "                  name='separation_layer_3')(layer_shared_1)\n",
    "\n",
    "layer_s_4 = Dense(mlp2_nodes_2*2, activation='relu',\n",
    "                  kernel_initializer=weight_initilizer,\n",
    "                  bias_initializer=bias_initializer,\n",
    "                  name='separation_layer_4')(layer_shared_1)\n",
    "\n",
    "\n",
    "out_layer_2 = Dense(1, activation='relu',\n",
    "                    kernel_initializer=weight_initilizer,\n",
    "                    bias_initializer=bias_initializer,\n",
    "                    name='SecondMoment')(layer_s_2)\n",
    "\n",
    "out_layer_3 = Dense(1, activation='linear',\n",
    "                    kernel_initializer=weight_initilizer,\n",
    "                    bias_initializer=bias_initializer,\n",
    "                    name='ThirdMoment')(layer_s_3)\n",
    "\n",
    "out_layer_4 = Dense(1, activation='relu',\n",
    "                    kernel_initializer=weight_initilizer,\n",
    "                    bias_initializer=bias_initializer,\n",
    "                    name='FourthMoment')(layer_s_4)\n",
    "\n",
    "model_central_moments = keras.Model(\n",
    "    inputs=[input_layer],\n",
    "    outputs=[out_layer_2, out_layer_3, out_layer_4], name='Three_Moments_Parallel'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = keras.Input(shape=(len(feature_variables),), name='Input')\n",
    "\n",
    "# weight_initilizer = 'glorot_normal' \n",
    "# bias_initializer = 'Zeros'\n",
    "\n",
    "\n",
    "# layer_shared_1 = Dense(16, activation='relu',\n",
    "#                   kernel_initializer=weight_initilizer,\n",
    "#                   bias_initializer=bias_initializer,\n",
    "#                   name='shared_layer')(input_layer)\n",
    "\n",
    "# # Separation layers\n",
    "# layer_s_2 = Dense(32, activation='relu',\n",
    "#                   kernel_initializer=weight_initilizer,\n",
    "#                   bias_initializer=bias_initializer,\n",
    "#                   name='separation_layer_2')(layer_shared_1)\n",
    "\n",
    "# layer_s_3 = Dense(32, activation='relu',\n",
    "#                   kernel_initializer=weight_initilizer,\n",
    "#                   bias_initializer=bias_initializer,\n",
    "#                   name='separation_layer_3')(layer_shared_1)\n",
    "\n",
    "# layer_s_4 = Dense(32, activation='relu',\n",
    "#                   kernel_initializer=weight_initilizer,\n",
    "#                   bias_initializer=bias_initializer,\n",
    "#                   name='separation_layer_4')(layer_shared_1)\n",
    "\n",
    "\n",
    "# out_layer_2 = Dense(1, activation='relu',\n",
    "#                     kernel_initializer=weight_initilizer,\n",
    "#                     bias_initializer=bias_initializer,\n",
    "#                     name='SecondMoment')(layer_s_2)\n",
    "\n",
    "# out_layer_3 = Dense(1, activation='linear',\n",
    "#                     kernel_initializer=weight_initilizer,\n",
    "#                     bias_initializer=bias_initializer,\n",
    "#                     name='ThirdMoment')(layer_s_3)\n",
    "\n",
    "# out_layer_4 = Dense(1, activation='relu',\n",
    "#                     kernel_initializer=weight_initilizer,\n",
    "#                     bias_initializer=bias_initializer,\n",
    "#                     name='FourthMoment')(layer_s_4)\n",
    "\n",
    "# model_central_moments = keras.Model(\n",
    "#     inputs=[input_layer],\n",
    "#     outputs=[out_layer_2, out_layer_3, out_layer_4], name='Three_Moments_Parallel'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Model Summary and visualization\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:17.226372Z",
     "start_time": "2021-06-14T13:16:16.997376Z"
    }
   },
   "outputs": [],
   "source": [
    "model_central_moments.summary()\n",
    "keras.utils.plot_model(model_central_moments, show_shapes=True, to_file=outdir + \"model_other_moments.png\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "config\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:17.666519Z",
     "start_time": "2021-06-14T13:16:17.653526Z"
    }
   },
   "outputs": [],
   "source": [
    "config.batch_size = len(train_X)\n",
    "config.n_epochs = 10000\n",
    "config.initial_learning_rate = 0.1\n",
    "config.loss = 'mse'\n",
    "\n",
    "config.early_stop_monitor = 'loss'\n",
    "config.min_delta = 0.001\n",
    "config.early_stop_patience = 500\n",
    "config.lr_reduce_monitor = 'loss'\n",
    "config.lr_reduce_factor = 0.1\n",
    "config.lr_reduce_patience = 50\n",
    "config.verbose = 0\n",
    "\n",
    "local_clbs = LocalCallBacks(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Compile the model\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:18.265325Z",
     "start_time": "2021-06-14T13:16:18.245296Z"
    }
   },
   "outputs": [],
   "source": [
    "model_central_moments.compile(\n",
    "    loss=[config.loss, config.loss, config.loss],\n",
    "    optimizer=Nadam(learning_rate=config.initial_learning_rate),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Train the model\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:16:18.850792Z",
     "start_time": "2021-06-14T13:16:18.837794Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y_dict = {'SecondMoment': train_y_dev[:,0].reshape(-1,1),\n",
    "                'ThirdMoment': train_y_dev[:,1].reshape(-1,1)\n",
    "                ,'FourthMoment': train_y_dev[:,2].reshape(-1,1)}\n",
    "\n",
    "test_y_dict = {'SecondMoment': test_y_dev[:,0].reshape(-1,1),\n",
    "                'ThirdMoment': test_y_dev[:,1].reshape(-1,1)\n",
    "                ,'FourthMoment': test_y_dev[:,2].reshape(-1,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:48:50.343286Z",
     "start_time": "2021-06-14T13:48:44.144716Z"
    }
   },
   "outputs": [],
   "source": [
    "model_central_moments_history = model_central_moments.fit(\n",
    "    train_X,\n",
    "    train_y_dict,\n",
    "    epochs=config.n_epochs,\n",
    "    batch_size=config.batch_size,\n",
    "    validation_data=(test_X, test_y_dict),\n",
    "    callbacks=[\n",
    "        local_clbs.early_stop_clbk,\n",
    "        local_clbs.lr_plan,\n",
    "        WandbCallback(),\n",
    "        TqdmCallback,\n",
    "    ],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:#51AFF9;'>\n",
    "Loss vs Epoch plot\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T13:48:50.645394Z",
     "start_time": "2021-06-14T13:48:50.344287Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize= (15,3))\n",
    "\n",
    "for label, ax in zip(train_y_dict.keys(), axes):\n",
    "\n",
    "    plot_model(\n",
    "        model_central_moments_history,\n",
    "        ax=ax,\n",
    "        loss_dict={\"loss\": f\"{label}_loss\", \"val_loss\": f\"val_{label}_loss\"},\n",
    "    )\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:#1B127A;'>\n",
    "Export\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:26:35.190673Z",
     "start_time": "2021-06-14T14:26:35.179707Z"
    }
   },
   "outputs": [],
   "source": [
    "model_first_moment.save(outdir+f'modelfirstmoment{file_suffix}')\n",
    "model_central_moments.save(outdir+f'modelcentralmoments{file_suffix}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.175px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
