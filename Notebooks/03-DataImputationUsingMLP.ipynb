{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T04:42:01.834014Z",
     "start_time": "2022-07-19T04:42:01.817516Z"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:17.114005Z",
     "start_time": "2022-10-22T03:45:16.943006Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import rmsp\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil\n",
    "import copy\n",
    "import pygeostat as gs\n",
    "from tqdm.notebook import trange\n",
    "tf.__version__\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:17.315505Z",
     "start_time": "2022-10-22T03:45:17.132005Z"
    }
   },
   "outputs": [],
   "source": [
    "rmsp.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:17.532330Z",
     "start_time": "2022-10-22T03:45:17.360881Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('../Tools'))\n",
    "from file_export import PickleExporter, FigureExporter\n",
    "from gaussian_mv import GmmUtility\n",
    "from lambda_distribution import GeneralizedLambdaDist\n",
    "from utility import get_lambdas_keras\n",
    "from utility import fix_ipython_autocomplete\n",
    "fix_ipython_autocomplete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:17.733794Z",
     "start_time": "2022-10-22T03:45:17.576261Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_axes(n_col, n_plots, figsize, **kwargs):\n",
    "\n",
    "    n_rows = n_plots // n_col + int(n_plots % n_col > 0)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_col, figsize=figsize, **kwargs)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    n_invisible = 0\n",
    "    if (n_plots % n_col) > 0:\n",
    "        n_invisible = n_col - n_plots % n_col\n",
    "\n",
    "        for ax in axes[-n_invisible:]:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "    return fig, axes[:len(axes) - n_invisible]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains a workflow to implement data imputation for North West Territories data set. RMSP is used instead of pygeostat where applicable to simplify the code and improve the performance.\n",
    "\n",
    "The data imputation is based on quantifying the conditional distribution of a missing variable. The conditional distribution is informed by the multivariate and spatial relationships. Since it is not feasible to model the full multivariate spatial distribution, the two main components are quantified separately and then merged/combined based on Bayesian updating. Collocated multivariate relationship and univariate spatial continuity of the missing variable are the two main components. \n",
    "\n",
    "In this notebook, MLP ANN networks are used to quantify the conditional moments based on homotopic multivariate relationships. The conditional moments are used to fit a parameteric Lambda distribution. The Lambda distribution is combined with the spatial conditional distribution (i.e. SK/normal equations) before being sampled to generate one realization of a missing value.\n",
    "\n",
    "Note: The tensorflow version should be 2.0 or newer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:19.366070Z",
     "start_time": "2022-10-22T03:45:19.201055Z"
    }
   },
   "outputs": [],
   "source": [
    "outdir = 'Output/Imputation_MLP/'\n",
    "data_dir = 'Output/DataInventory/'\n",
    "mlp_dir = 'Output/LambdaDistributionMl/'\n",
    "gs.mkdir(outdir)\n",
    "\n",
    "inputdir = 'data/NWTData'\n",
    "\n",
    "gs.Parameters['data.tmin'] = -998\n",
    "gs.Parameters['data.null'] = -999\n",
    "aspects = {'xy': 2, 'xz': 20, 'yz': 6}\n",
    "\n",
    "cmap = 'RdYlGn_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:19.582275Z",
     "start_time": "2022-10-22T03:45:19.422969Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_data = PickleExporter(outdir)\n",
    "save_figure = FigureExporter(outdir)\n",
    "save_figure_paper = FigureExporter(\n",
    "    \"../../JournalPapers/ImputationUsingLambdaDistAndMl/Latex/elsarticle-template/Figures_Ni/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#5177F9;'> Helper function </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:19.999498Z",
     "start_time": "2022-10-22T03:45:19.838999Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_axis_label_font(ax, fontsize=12, title=True, prefix=''):\n",
    "    label = ax.get_xlabel()\n",
    "    if len(label)>0:\n",
    "        label=prefix + label\n",
    "    ax.set_xlabel(label, fontsize=fontsize)\n",
    "    label = ax.get_ylabel()\n",
    "    if len(label)>0:\n",
    "        label=prefix + label\n",
    "    ax.set_ylabel(label, fontsize=fontsize)\n",
    "    if title:\n",
    "        ax.set_title(ax.get_title(), fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:20.261876Z",
     "start_time": "2022-10-22T03:45:20.103877Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_cabr_label_font(fig, fontsize=11, prefix=''):\n",
    "    for child in fig.get_children():\n",
    "        if 'cbar' in type(child).__name__.lower():\n",
    "            label = child.get_ylabel()\n",
    "            child.set_ylabel(prefix+label, fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:20.509535Z",
     "start_time": "2022-10-22T03:45:20.344036Z"
    }
   },
   "outputs": [],
   "source": [
    "def scaplot_compare(data, variables, prefix='', **kwargs):\n",
    "    n_var = len(variables)\n",
    "    n_plots = int((n_var * (n_var-1))/2)\n",
    "\n",
    "    fig, axes = create_axes(n_plots,n_plots,(12,3))\n",
    "    count = 0\n",
    "    for i in range(n_var-1):\n",
    "        for j in range(i+1,n_var):\n",
    "            data.scatplot(variables[i], variables[j], ax=axes[count],cmap=cmap, stats=['count', 'corr'], **kwargs)\n",
    "            set_axis_label_font(axes[count], prefix=prefix)\n",
    "            count+=1\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:21.342523Z",
     "start_time": "2022-10-22T03:45:21.157607Z"
    }
   },
   "outputs": [],
   "source": [
    "data = rmsp.from_pickle(data_dir+'PooledData.pkl')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:21.652594Z",
     "start_time": "2022-10-22T03:45:21.483595Z"
    }
   },
   "outputs": [],
   "source": [
    "response_variables = rmsp.from_pickle(data_dir+'response_variables.pkl')\n",
    "missing_variables = rmsp.from_pickle(data_dir+'missing_variables.pkl')\n",
    "n_var_miss = len(missing_variables)\n",
    "variables = response_variables + missing_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declustering, Despiking and NS transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:22.362216Z",
     "start_time": "2022-10-22T03:45:22.128218Z"
    }
   },
   "outputs": [],
   "source": [
    "search = rmsp.Search(min_comps=1, max_comps=1, ranges=[50000.0] * 3)\n",
    "est = rmsp.NNEstimator(search)\n",
    "\n",
    "wts = []\n",
    "for var in variables:\n",
    "    est.estimate(data, data, var, accumulate_weights=True)\n",
    "    data[var + \"_wt\"] = est.get_cumulative_weights()\n",
    "    wts.append(var + \"_wt\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:24.826651Z",
     "start_time": "2022-10-22T03:45:22.390216Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for orient in (\"xy\", \"xz\", \"yz\"):\n",
    "    fig, axes = rmsp.ImageGrid(\n",
    "        1,\n",
    "        len(variables),\n",
    "        figsize=(len(variables) * 5, 12),\n",
    "        cbar_mode=\"each\",\n",
    "        axes_pad=(0.6, 0.4),\n",
    "    )\n",
    "    for ax, var in zip(axes, variables):\n",
    "        data.sectionplot(\n",
    "            orient=orient,\n",
    "            var=var + \"_wt\",\n",
    "            s=10,\n",
    "            ax=ax,\n",
    "            grid=True,\n",
    "            tickangs=(45, 45),\n",
    "            missing_color=\"r\",\n",
    "            aspect=aspects[orient],\n",
    "        )\n",
    "        set_axis_label_font(ax)\n",
    "    set_cabr_label_font(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:25.012591Z",
     "start_time": "2022-10-22T03:45:24.828122Z"
    }
   },
   "outputs": [],
   "source": [
    "dsp = rmsp.DespikeMVSpatial(\n",
    "    num_neighbors=min(len(data), 10),\n",
    "    despike_level=0.00001,\n",
    "    spike_epsilon=0.00001,\n",
    "    wt_to_random = 0.5\n",
    ")\n",
    "\n",
    "data[variables] = dsp.fit_transform(\n",
    "    data, variables\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:26.500591Z",
     "start_time": "2022-10-22T03:45:25.014092Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = create_axes(3,len(variables), (14,3))\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    data.cdfplot(variable, variable + \"_wt\", ax=axes[i], log=False, lw=2, grid=True)\n",
    "    axes[i].set_xlabel(axes[i].get_xlabel() + ' (%)')\n",
    "    set_axis_label_font(axes[i])\n",
    "\n",
    "# save_figure_paper('CSHistBeforeNS.pdf')\n",
    "save_figure_paper('CdfBeforeNS.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:26.701969Z",
     "start_time": "2022-10-22T03:45:26.502091Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ns = data.copy()\n",
    "\n",
    "ns_transformers = {}\n",
    "\n",
    "for var in variables:\n",
    "    ns_transformer = rmsp.NSTransformer()\n",
    "    data_ns[var] = ns_transformer.fit_transform(data[var], data[var+'_wt'])\n",
    "    ns_transformers.update({var:ns_transformer})\n",
    "\n",
    "data_ns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:27.972469Z",
     "start_time": "2022-10-22T03:45:26.703470Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = create_axes(3,len(variables), (14,3))\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    data_ns.histplot(variable, ax=axes[i], face_c='lightgreen', edge_c='k', xlabel=f'Ns:{variable}')\n",
    "    set_axis_label_font(axes[i])\n",
    "save_figure_paper('CSHistAfterNS.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location map for NScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:45:33.552498Z",
     "start_time": "2022-10-22T03:45:27.973473Z"
    }
   },
   "outputs": [],
   "source": [
    "stat = data_ns.describe()\n",
    "for orient in (\"xy\", \"xz\", \"yz\"):\n",
    "    fig, axes = rmsp.ImageGrid(\n",
    "        1,\n",
    "        n_var_miss,\n",
    "        figsize=(n_var_miss * 5, 12),\n",
    "        cbar_mode=\"each\",\n",
    "        axes_pad=(0.6, 0.4),\n",
    "    )\n",
    "\n",
    "    stat = data_ns.describe()\n",
    "\n",
    "    for ax, var in zip(axes, missing_variables):\n",
    "        data_ns.sectionplot(\n",
    "            var,\n",
    "            orient=orient,\n",
    "            s=15,\n",
    "            ax=ax,\n",
    "            grid=True,\n",
    "            clim=[-3, 3],\n",
    "            tickangs=(45, 45),\n",
    "            missing_color=\"r\",\n",
    "            aspect=aspects[orient],\n",
    "        )\n",
    "        if orient == \"xy\":\n",
    "            ax.text(\n",
    "                0.1,\n",
    "                0.9,\n",
    "                \"n = %d\" % (stat[var][\"count\"]),\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=13,\n",
    "            )\n",
    "        else:\n",
    "            ax.text(\n",
    "                0.1,\n",
    "                0.1,\n",
    "                f\"{aspects[orient]}x vertical exageration\",\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=13,\n",
    "            )\n",
    "        set_axis_label_font(ax)\n",
    "    set_cabr_label_font(fig, prefix='NS:')\n",
    "    plt.tight_layout(w_pad=2)\n",
    "    save_figure_paper(f'locmap_ns_{orient}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate relationship plots (After NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:28.539582Z",
     "start_time": "2022-10-12T11:45:28.370083Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = 'RdYlGn_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:30.879682Z",
     "start_time": "2022-10-12T11:45:28.540583Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = data_ns[missing_variables].notna().all(axis=1)\n",
    "fig = data_ns[mask].scatplots(\n",
    "    variables=variables,\n",
    "    figsize=(8, 8),\n",
    "    s=5,\n",
    "    num_sample=7000,\n",
    "    axes_pad=(0.15, 0.15),\n",
    "    stats=['count','rankcorr', 'corr'],\n",
    "    cbar=True,\n",
    "    lims = {var: (-3.5,3.5) for var in variables},\n",
    "    cmap=cmap\n",
    ")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    set_axis_label_font(ax, prefix='NS:')\n",
    "    ax.grid()\n",
    "    \n",
    "save_figure_paper(\n",
    "    r\"CSMV1.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data spacing analysis\n",
    "\n",
    "Data spacing analysis for variables with missing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:31.065582Z",
     "start_time": "2022-10-12T11:45:30.880584Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = data_ns.horizontal_spacing(n_nearest=1, var=missing_variables[0], nexcept=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:31.623581Z",
     "start_time": "2022-10-12T11:45:31.066584Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_column = ds.columns[-1]\n",
    "_ = ds.sectionplot(ds_column, s=5, tickangs=(45,45), cmap='Spectral_r')\n",
    "_, ax = ds.cdfplot(ds_column, annotate_stats=[\"p0.05\",\"p25\", \"p50\", \"p75\", \"p95\"], log = True, figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental variogram calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:31.794082Z",
     "start_time": "2022-10-12T11:45:31.625583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the average nearest distance as a measure of average data spacing\n",
    "lag_length = np.mean(ds[ds.columns[-1]])\n",
    "\n",
    "x_range =  (data_ns[data_ns.x].max() - data_ns[data_ns.x].min())/4 # Limitted the range\n",
    "y_range =  (data_ns[data_ns.y].max() - data_ns[data_ns.y].min())/4\n",
    "\n",
    "n_lag_x = int(x_range/lag_length)\n",
    "n_lag_y = int(y_range/lag_length)\n",
    "\n",
    "\n",
    "nlags_horz = 12\n",
    "nlags_vert = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:31.964082Z",
     "start_time": "2022-10-12T11:45:31.795083Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_vario_search = []\n",
    "\n",
    "# Horizontal\n",
    "lags, tols = rmsp.Lags.merge_lags_tols(\n",
    "    [\n",
    "        # rmsp.Lags(lag_length * 0.5, lag_length * 0.5 * 0.45, 1),\n",
    "        rmsp.Lags(lag_length, lag_length * 0.45, nlags_horz),\n",
    "    ]\n",
    ")\n",
    "search_vario_horz = rmsp.ExpVarioSearch(0, 0, lags, tols, azmtol=90, incltol=90)\n",
    "exp_vario_search.append(search_vario_horz)\n",
    "\n",
    "# Vertical\n",
    "lag_vert = rmsp.Lags(1, 1 * 0.75, nlags_vert)\n",
    "lags, tols = lag_vert.get_lags_tols()\n",
    "search_vario_horz = rmsp.ExpVarioSearch(0, 90, lags, tols, azmtol=45, incltol=15)\n",
    "exp_vario_search.append(search_vario_horz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:34.165082Z",
     "start_time": "2022-10-12T11:45:31.965083Z"
    }
   },
   "outputs": [],
   "source": [
    "vario_exp = {}\n",
    "for var in missing_variables:\n",
    "    vario_exp[var] = rmsp.ExpVario(\"traditional\").calculate(\n",
    "        data_ns, var, searches=exp_vario_search\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:35.653082Z",
     "start_time": "2022-10-12T11:45:34.166084Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "variogram_names = ['Horizontal', 'Vertical']\n",
    "\n",
    "for i, var in enumerate(missing_variables):\n",
    "    data_var = vario_exp[var].data\n",
    "    for index in data_var['Search Index'].unique():\n",
    "        mask = data_var['Search Index'] == index\n",
    "        vario_exp[var].plot(\n",
    "            search_index=index,\n",
    "            ax=axes[int(index), i],\n",
    "            ylim=(0, 1.2),\n",
    "            title=(f\"{var} ({variogram_names[i]})\"),\n",
    "            pairs_bar=True,\n",
    "            c=f'C{i}',\n",
    "            ms=5\n",
    "        )\n",
    "        set_axis_label_font(axes[int(index), i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variogram Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:35.870082Z",
     "start_time": "2022-10-12T11:45:35.654084Z"
    }
   },
   "outputs": [],
   "source": [
    "vario_models = {}\n",
    "\n",
    "num_struct = 2\n",
    "\n",
    "range3_dict = {'Fe': [[8, 9], [10, 11] ], 'SiO2': [[10, 12], [12, 14]]}\n",
    "\n",
    "for var in missing_variables:\n",
    "\n",
    "    \n",
    "    vario_model = rmsp.VarioModel.fit_experimental(\n",
    "        vario_exp[var],\n",
    "        num_struct=num_struct,\n",
    "        nugget=[0.05, 0.05],\n",
    "        shapes=\"exponential\",\n",
    "        var_contribs=[[0.0, 1.0]] * num_struct,\n",
    "        angle1=[0.0] * num_struct,  # a list with length 2 can be used to pass range\n",
    "        angle2=[0.0] * num_struct,\n",
    "        angle3=[0.0] * num_struct,\n",
    "        angles_fixed_across=True,\n",
    "        range1=[[40, 100], [100, 300.0]],\n",
    "        # range2=[[10, 20000.0], [20000, 80000.0]],\n",
    "        range3=range3_dict[var],\n",
    "        ranges12_bounds=1,\n",
    "        ranges13_bounds=None,\n",
    "        invdist_wt=False,\n",
    "        numpairs_wt=True,\n",
    "        consider_early_exit=False,\n",
    "        try_unique_dir_lock=True,\n",
    "        lock_min_range_to_close_lag=False,\n",
    "        max_no_improvement=500,\n",
    "        minpairs=50,\n",
    "    )\n",
    "\n",
    "    vario_models.update({var: vario_model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:36.056132Z",
     "start_time": "2022-10-12T11:45:35.871085Z"
    }
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for var, varmodel in vario_models.items():\n",
    "    df = vario_models[var].to_table()\n",
    "    df.columns = pd.MultiIndex.from_tuples(((var, x) for x in df.columns))\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:39.280082Z",
     "start_time": "2022-10-12T11:45:36.057083Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "rmsp.GlobalParams[\"plotting.varioplot.gammasize\"] = 1\n",
    "for i, var in enumerate(missing_variables):\n",
    "    data_var = vario_exp[var].data\n",
    "    for index in data_var[\"Search Index\"].unique():\n",
    "        mask = data_var[\"Search Index\"] == index\n",
    "        azim = data_var[mask].Azimuth.mean()\n",
    "        incl = data_var[mask].Inclination.mean()\n",
    "        vario_exp[var].plot(\n",
    "            search_index=index,\n",
    "            ax=axes[int(index), i],\n",
    "            ylim=(0, 1.2),\n",
    "            title=var,\n",
    "            label = f\"(azm: {azim:.2f}, incl: {incl:.2f})\",\n",
    "            pairs_bar=True,\n",
    "            c=f\"C{i}\",\n",
    "            tickangs=(45, 0),\n",
    "            ms=5,\n",
    "        )\n",
    "        vario_models[var].plot_draw(\n",
    "            ax=axes[int(index), i], azm=azim, incl=incl, lw=2, c=f\"C{i}\", ls=\"--\"\n",
    "        )\n",
    "        axes[int(index), i].legend(fontsize=12)\n",
    "        set_axis_label_font(axes[int(index), i])\n",
    "plt.tight_layout()\n",
    "save_figure_paper(\"CSVarg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting GMM \n",
    "\n",
    "The fitted GMM will be used only as a cross reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:54.020654Z",
     "start_time": "2022-10-12T11:45:39.281083Z"
    }
   },
   "outputs": [],
   "source": [
    "gmm_model = rmsp.GMM().fit(data_ns[variables], num_kernels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:54.206621Z",
     "start_time": "2022-10-12T11:45:54.021653Z"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from test_suite import GmmUtilityTest\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(GmmUtilityTest)\n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:45:54.377121Z",
     "start_time": "2022-10-12T11:45:54.208123Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_list = []\n",
    "cov_list = []\n",
    "contrib_list = []\n",
    "\n",
    "for kernel in gmm_model.kernels:\n",
    "    mean_list.append(kernel.mean)\n",
    "    cov_list.append(kernel.cov)\n",
    "    contrib_list.append(kernel.wt)\n",
    "    \n",
    "gmm_util = GmmUtility(\n",
    "    data=data_ns,\n",
    "    variable_names=variables,\n",
    "    mean_vector_list=mean_list,\n",
    "    covariance_matrix_list=cov_list,\n",
    "    contribution_list=contrib_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:46:00.964121Z",
     "start_time": "2022-10-12T11:45:54.378122Z"
    }
   },
   "outputs": [],
   "source": [
    "gmm_util.summary_plot(cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting MLP for the missing variables\n",
    "\n",
    "\n",
    "Setting parameters to model and train an MLP ANN that estimates the first four moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:46:01.382609Z",
     "start_time": "2022-10-12T11:46:00.965123Z"
    }
   },
   "outputs": [],
   "source": [
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:46:06.563279Z",
     "start_time": "2022-10-12T11:46:06.389779Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_conditional_moments(input_vals, model_first_moment, model_central_moments, reference_data, label_variable):\n",
    "    \"\"\"Calculate conditional moments\"\"\"\n",
    "    mean = model_first_moment.predict(input_vals)[0][0]\n",
    "    variance, skewness, kurtosis = model_central_moments.predict(\n",
    "        input_vals\n",
    "    )\n",
    "    variance = variance[0][0]\n",
    "    skewness = skewness[0][0]\n",
    "    kurtosis = kurtosis[0][0]\n",
    "\n",
    "    max_var = reference_data[label_variable].max()\n",
    "    min_var = reference_data[label_variable].min()\n",
    "    span = max_var - min_var\n",
    "    max_var = max_var + 0.01*span\n",
    "    min_var = min_var - 0.01*span\n",
    "\n",
    "    mean = min(mean, max_var)\n",
    "    mean = max(mean, min_var)\n",
    "\n",
    "    try:\n",
    "        skewness = skewness / pow(variance, 1.5)\n",
    "        kurtosis = kurtosis / pow(variance, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(input_vals)\n",
    "        variance = 1.0\n",
    "        skewness = 0\n",
    "        kurtosis = 3.0\n",
    "\n",
    "    skewness = max(skewness, -1.1)\n",
    "    skewness = min(skewness, 1.5)\n",
    "\n",
    "    kurtosis = max(kurtosis, 1.8)\n",
    "    kurtosis = min(kurtosis, 5.9)\n",
    "\n",
    "    return mean, variance, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:46:18.941274Z",
     "start_time": "2022-10-12T11:46:18.770273Z"
    }
   },
   "outputs": [],
   "source": [
    "# add a unqie hash column\n",
    "data_ns['Hash'] = pd.util.hash_pandas_object(data_ns[[data_ns.dhid, data_ns.x, data_ns.y]], hash_key='0314')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:46:35.383844Z",
     "start_time": "2022-10-12T11:46:35.206844Z"
    }
   },
   "outputs": [],
   "source": [
    "# mlp execution function\n",
    "def execute_mlp_for_conditional_mv(\n",
    "    missing_variable, response_variables, input_data, mlp2_nodes_1=64, mlp2_nodes_2=16\n",
    "):\n",
    "    label_variable_mlcon = missing_variable\n",
    "    feature_variables_mlcon = response_variables\n",
    "    outdir_mlcon = f\"Output/MlForConditionalDistCaseStudy/{label_variable_mlcon}/\"\n",
    "\n",
    "    data_dir_mlcon = outdir\n",
    "    input_data_pkl = f\"data_ns_{label_variable_mlcon}.pkl\"\n",
    "    pickle_data(input_data, input_data_pkl, clean_name=False)\n",
    "\n",
    "    input_template = \"02-MlForConditionalDistributionTemplate.ipynb\"\n",
    "    notebook = input_template.replace(\"Template\", missing_variable)\n",
    "\n",
    "    data_out_mlcon = \"data_out.pkl\"\n",
    "\n",
    "    # execute notebook\n",
    "    pm_exec_info = pm.execute_notebook(\n",
    "        input_template,\n",
    "        notebook,\n",
    "        parameters=dict(\n",
    "            outdir=outdir_mlcon,\n",
    "            data_dir=data_dir_mlcon,\n",
    "            ns_data_pkl=input_data_pkl,\n",
    "            label_variable=label_variable_mlcon,\n",
    "            feature_variables=feature_variables_mlcon,\n",
    "            out_file=data_out_mlcon,\n",
    "            mlp2_nodes_1 = mlp2_nodes_1,\n",
    "            mlp2_nodes_2 = mlp2_nodes_2\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    from utility import make_html\n",
    "    make_html(notebook, notebook.replace('.ipynb', '.html'))\n",
    "    \n",
    "    rmsp.remove_file(notebook)\n",
    "\n",
    "    model_first_moment = keras.models.load_model(outdir_mlcon + f\"modelfirstmoment\")\n",
    "    model_central_moments = keras.models.load_model(\n",
    "        outdir_mlcon + f\"modelcentralmoments\"\n",
    "    )\n",
    "\n",
    "    return model_first_moment, model_central_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:46:35.755099Z",
     "start_time": "2022-10-12T11:46:35.583100Z"
    }
   },
   "outputs": [],
   "source": [
    "models_mpl = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Missing variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-09T03:54:10.565396Z",
     "start_time": "2022-10-09T03:52:52.374282Z"
    }
   },
   "outputs": [],
   "source": [
    "model_first_moment, model_central_moments = execute_mlp_for_conditional_mv(\n",
    "    missing_variables[0], response_variables, data_ns, mlp2_nodes_1=8, mlp2_nodes_2=8\n",
    ")\n",
    "\n",
    "models_mpl[missing_variables[0]] = [model_first_moment, model_central_moments]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-09T04:32:49.160480Z",
     "start_time": "2022-10-09T04:32:08.602866Z"
    }
   },
   "outputs": [],
   "source": [
    "model_first_moment, model_central_moments = execute_mlp_for_conditional_mv(\n",
    "    missing_variables[1],\n",
    "    response_variables + [missing_variables[0]],\n",
    "    data_ns,\n",
    "    mlp2_nodes_1=16,\n",
    "    mlp2_nodes_2=4,\n",
    ")\n",
    "\n",
    "models_mpl[missing_variables[1]] = [model_first_moment, model_central_moments]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP and Lambda distribution check \n",
    "\n",
    "This section is a code snippet to use an already fitted MLP model to get the conditional moments of a missing variable. Then, lambda distribution is used to parametrize the conditional distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:48:25.376086Z",
     "start_time": "2022-10-12T11:48:25.018819Z"
    }
   },
   "outputs": [],
   "source": [
    "class_name = 'Ia'\n",
    "mlp_model = keras.models.load_model(mlp_dir+f'Lambda_{class_name}_Keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:48:26.041036Z",
     "start_time": "2022-10-12T11:48:25.857036Z"
    }
   },
   "outputs": [],
   "source": [
    "out_dir_lambda = \"LambdaFitResults/\"\n",
    "try:\n",
    "    shutil.rmtree(out_dir_lambda)\n",
    "except:\n",
    "    pass\n",
    "rmsp.make_dir(out_dir_lambda)\n",
    "save_figure_check = FigureExporter(os.path.join(outdir, \"LambdaFitResults/\"))\n",
    "def get_simulated_value(a1, a2, a3, a4, out_dir, variable_name):\n",
    "    a4 = min(a4, 4.5)\n",
    "\n",
    "    # Fit the lambda distribution\n",
    "    lambdas = get_lambdas_keras(a1, a2, a3, a4, mlp_model)\n",
    "    gld = GeneralizedLambdaDist(*lambdas)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    # lambda distribution pdf\n",
    "    ax = gld.pdf_plot(ax=axes[0], return_ax=True)\n",
    "    axes[0].set_xlabel(r\"$Y_m$\", fontsize=12)\n",
    "    axes[0].set_ylabel(r\"pdf\", fontsize=12)\n",
    "    text = f\"mean: {a1:.2f}\\n\"\n",
    "    text += f\"$\\sigma$: {np.sqrt(a2):.2}\\n\"\n",
    "    text += f\"$skew$: {a3:.2f}\\n\"\n",
    "    text += f\"$kurtosis$: {a4:.2f}\"\n",
    "    ax.text(0.6, 0.7, text, transform=ax.transAxes, ha=\"left\")\n",
    "\n",
    "    gld.dist_plot(cdf=False, ax=axes[1], color=\"green\")\n",
    "    axes[1].set_xlabel(r\"$Y_m$\", fontsize=12)\n",
    "\n",
    "    save_figure(\"Conditional_comparison_{}_{:.2f}.png\".format(variable_name, a1))\n",
    "\n",
    "    return gld.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:48:28.690110Z",
     "start_time": "2022-10-12T11:48:26.521108Z"
    }
   },
   "outputs": [],
   "source": [
    "for _, row in data_ns.head(10).iterrows():\n",
    "\n",
    "    if pd.isna(row[[missing_variables[0]]]).any():\n",
    "\n",
    "        a1,a2, a3, a4 = get_conditional_moments(\n",
    "            row[response_variables].values.reshape(-1, len(response_variables)),\n",
    "            *models_mpl[missing_variables[0]],\n",
    "            data_ns,\n",
    "            missing_variables[0]\n",
    "        )\n",
    "        print(a1, a2, a3, a4)\n",
    "        get_simulated_value(\n",
    "            a1, a2, a3, a4, out_dir_lambda, variable_name=missing_variables[0],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation (One Example Realization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T02:58:47.231183Z",
     "start_time": "2022-10-15T02:58:47.054683Z"
    }
   },
   "outputs": [],
   "source": [
    "from probability_updating import (\n",
    "    update_bayesian_pr, update_bayesian_ind\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:35:56.742517Z",
     "start_time": "2022-10-13T23:35:56.574487Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate(cdf, x):\n",
    "    return np.interp(np.random.rand(), cdf, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Updating function (using CDF)\n",
    "\n",
    "In this section, permanence of ratio (PR) are used to combine the fitted lambda distribution, the conditional Gaussian distribution and the prior representative normal distribution. \n",
    "\n",
    "Below is an example that uses four example moments to fit a lambda distribution and then combined with an example conditional Gaussian distribution using PR to get the final updated distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T02:58:59.019609Z",
     "start_time": "2022-10-15T02:58:58.728517Z"
    }
   },
   "outputs": [],
   "source": [
    "lambdas = get_lambdas_keras(1.384, 1.071*1.071, -0.466, 2.978, mlp_model)\n",
    "gld = GeneralizedLambdaDist(*lambdas)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(7,5))\n",
    "\n",
    "ax.set_title('Conditional Independence', fontsize= 14)\n",
    "x_vals, F_gld, F_spatial, F_global, cdf_updated = update_bayesian_pr(gld, 1.15, 1.8, n_sample = 100)\n",
    "ax.plot(x_vals, F_gld, 'g', label='MV')\n",
    "ax.plot(x_vals, F_spatial, 'r', label = 'Spatial')\n",
    "ax.plot(x_vals, F_global, 'gray', label = 'global')\n",
    "ax.plot(x_vals, cdf_updated, 'k', label = 'updated')\n",
    "ax.plot([-8,8], [1,1], c='gray', lw=2)\n",
    "ax.set_xlim([-6,6])\n",
    "ax.set_ylim([0,1.1])\n",
    "ax.legend(fontsize= 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the imputation work flow\n",
    "\n",
    "Study one realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:48:33.778866Z",
     "start_time": "2022-10-12T11:48:33.581716Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keep the null index datafarame\n",
    "data_imputation = data_ns.copy()\n",
    "data_imputation['Missing'] = 0\n",
    "\n",
    "mask = data_imputation[missing_variables].isna().any(axis=1)\n",
    "data_imputation.loc[mask, 'Missing'] = 1\n",
    "\n",
    "data_imputation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:48:34.287438Z",
     "start_time": "2022-10-12T11:48:34.098939Z"
    }
   },
   "outputs": [],
   "source": [
    "spatial_dict = {\n",
    "    var: {data_ns.x: [], data_ns.y: [], data_ns.z: [], \"Estimate\": [], \"Variance\": []} for var in missing_variables\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:55:50.851118Z",
     "start_time": "2022-10-12T11:48:34.354913Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out_dir_imputation_plots = os.path.join(outdir, \"ImputedFigures\")\n",
    "try:\n",
    "    shutil.rmtree(out_dir_imputation_plots)\n",
    "except:\n",
    "    pass\n",
    "rmsp.make_dir(out_dir_imputation_plots)\n",
    "\n",
    "# previously imputed variable will be added to the response variables\n",
    "response_var_dict = {\n",
    "    missing_variables[0]: response_variables,\n",
    "    missing_variables[1]: response_variables + [missing_variables[0]],\n",
    "}\n",
    "\n",
    "item = 0\n",
    "for variable in missing_variables:\n",
    "\n",
    "    vario_model = vario_models[variable]\n",
    "#     search = rmsp.Search.from_vario_ranges(vario_model)\n",
    "    search = rmsp.Search([0.0] * 3, [100.0] * 3, min_comps=1, max_comps=100)\n",
    "    krig = rmsp.KrigeEstimator().set_params(\n",
    "        search, vario_model, \"sk\", sk_mean=np.nanmean(data_imputation[variable])\n",
    "    )\n",
    "\n",
    "    # Shuffle data\n",
    "    data_imputation_shuffled = data_imputation.sample(frac=1).reset_index(drop=False)\n",
    "\n",
    "    for idx, row in data_imputation_shuffled.iterrows():\n",
    "        \n",
    "        index = row['index']\n",
    "\n",
    "        spatial_dict[variable][data_ns.x].append(row[data_ns.x])\n",
    "        spatial_dict[variable][data_ns.y].append(row[data_ns.y])\n",
    "        spatial_dict[variable][data_ns.z].append(row[data_ns.z])\n",
    "\n",
    "        if pd.isna(row[variable]):\n",
    "\n",
    "            # mask missing location to implement kriging\n",
    "            mask = data_imputation[\"Hash\"] == row[\"Hash\"]\n",
    "            result = krig.estimate(\n",
    "                data_imputation.loc[mask],\n",
    "                data_imputation.loc[~mask],\n",
    "                variable,\n",
    "                output=[\"estimate\", \"estimate_var\"],\n",
    "            )\n",
    "\n",
    "            spatial_mean, spatial_variance = (\n",
    "                result[\"estimate\"].values[0],\n",
    "                result[\"estimate_var\"].values[0],\n",
    "            )\n",
    "\n",
    "            spatial_dict[variable][\"Estimate\"].append(spatial_mean)\n",
    "            spatial_dict[variable][\"Variance\"].append(spatial_variance)\n",
    "\n",
    "            # Get the conditioning data for GMM\n",
    "            conditioning_data = [\n",
    "                None if math.isnan(val) else val for val in row[gmm_util.variable_names]\n",
    "            ]\n",
    "            # Get the uni/bivariate conditional distribution based on the GMM components\n",
    "            (\n",
    "                cond_means,\n",
    "                cond_covariances,\n",
    "                cond_contributions,\n",
    "            ) = gmm_util.get_conditional_pdf(conditioning_data=conditioning_data)\n",
    "\n",
    "            # Grab the marginal univariate GMM componenets (first variable)\n",
    "            cond_means = np.array(cond_means)\n",
    "            cond_means = cond_means[:, 0].reshape(gmm_util.n_components, 1)\n",
    "            cond_covariances = np.array(cond_covariances)\n",
    "            cond_covariances = cond_covariances[:, 0, 0].reshape(\n",
    "                gmm_util.n_components, 1, 1\n",
    "            )\n",
    "\n",
    "            # use the\n",
    "            a1, a2, a3, a4 = get_conditional_moments(\n",
    "                row[response_var_dict[variable]].values.reshape(\n",
    "                    -1, len(response_var_dict[variable])\n",
    "                ),\n",
    "                *models_mpl[variable],\n",
    "                data_ns,\n",
    "                variable,\n",
    "            )\n",
    "\n",
    "            if a2 == 0:\n",
    "                print(\n",
    "                    a1,\n",
    "                    a2,\n",
    "                    a3,\n",
    "                    a4,\n",
    "                    index,\n",
    "                    row[response_var_dict[variable]].values.reshape(\n",
    "                        -1, len(response_var_dict[variable])\n",
    "                    ),\n",
    "                )\n",
    "                # a1, a2, a3, a4 = gmm_util.get_moments(\n",
    "                #     cond_means, cond_covariances, cond_contributions\n",
    "                # )\n",
    "\n",
    "            # Fit the lambda distribution given the first four moments\n",
    "            lambdas = get_lambdas_keras(a1, a2, a3, a4, mlp_model)\n",
    "\n",
    "            gld = GeneralizedLambdaDist(*lambdas)\n",
    "\n",
    "            x_vals, F_gld, F_spatial, F_global, F_updated = update_bayesian_pr(\n",
    "                gld, spatial_mean=spatial_mean, spatial_variance=spatial_variance\n",
    "            )\n",
    "\n",
    "            data_imputation.loc[index, variable] = simulate(F_updated, x_vals)\n",
    "\n",
    "            item += 1\n",
    "            # Plots\n",
    "            if item % 10 == 0:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "                ax = axes[0]\n",
    "                # lambda distribution pdf\n",
    "                _ = gld.pdf_plot(ax=ax, return_ax=False)\n",
    "                # Marginal/conditional GMM pdf\n",
    "                GmmUtility.univariate_pdf_from_mixture_plot(\n",
    "                    cond_means,\n",
    "                    cond_covariances,\n",
    "                    cond_contributions,\n",
    "                    variable_name=variable,\n",
    "                    ax=ax,\n",
    "                )\n",
    "                ax.set_title(\n",
    "                    \"Conditional distribution (GMM and lamda distribution)\", fontsize=13\n",
    "                )\n",
    "\n",
    "                ax = axes[1]\n",
    "                ax.plot(x_vals, F_gld, \"g\", label=r\"Lambda Distribution\")\n",
    "                ax.plot(\n",
    "                    x_vals,\n",
    "                    F_spatial,\n",
    "                    \"r\",\n",
    "                    label=r\"Spatial ($\\mu:${:.2f}, $\\sigma^2:${:.2f})\".format(\n",
    "                        spatial_mean, spatial_variance\n",
    "                    ),\n",
    "                )\n",
    "                ax.plot(x_vals, F_global, \"gray\", label=\"Global\")\n",
    "                ax.plot(x_vals, F_updated, \"blue\", label=\"Updated\")\n",
    "                ax.plot([-8, 8], [1, 1], c=\"gray\", lw=2)\n",
    "                ax.set_xlim([-6, 6])\n",
    "                ax.set_xlabel(variable, fontsize=12)\n",
    "                ax.set_ylim([0, 1.1])\n",
    "                ax.set_ylabel(\"Cumulative Distribution Function (CDF)\", fontsize=12)\n",
    "                ax.legend(fontsize=12, loc=\"center left\")\n",
    "                ax.set_title(\"Bayesian Updating\", fontsize=13)\n",
    "\n",
    "                gs.export_image(\n",
    "                    os.path.join(\n",
    "                        out_dir_imputation_plots,\n",
    "                        \"Conditional_comparison_{}_{:g}.png\".format(variable, item),\n",
    "                    )\n",
    "                )\n",
    "                plt.show()\n",
    "        else:\n",
    "            spatial_dict[variable][\"Estimate\"].append(np.nan)\n",
    "            spatial_dict[variable][\"Variance\"].append(np.nan)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there is any imputation issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:55:51.052618Z",
     "start_time": "2022-10-12T11:55:50.852618Z"
    }
   },
   "outputs": [],
   "source": [
    "for var in missing_variables:\n",
    "    mask = pd.isna(data_imputation[var])\n",
    "    display(data_imputation[mask])\n",
    "    assert len(data_imputation[mask]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the location map for the kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:55:52.571619Z",
     "start_time": "2022-10-12T11:55:51.054118Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for orient in (\"xy\", \"xz\", \"yz\"):\n",
    "    fig, axes = rmsp.ImageGrid(\n",
    "        1,\n",
    "        len(missing_variables),\n",
    "        figsize=(n_var_miss * 5, 12),\n",
    "        cbar_mode=\"each\",\n",
    "        axes_pad=(0.6, 0.4),\n",
    "    )\n",
    "\n",
    "    for ax, var in zip(axes, missing_variables):\n",
    "\n",
    "        point_data = pd.DataFrame(spatial_dict[var])\n",
    "\n",
    "        point_data = rmsp.PointData(point_data, x=data_ns.x, y=data_ns.y, z=data_ns.z)\n",
    "\n",
    "        point_data.sectionplot(\n",
    "            ax=ax,\n",
    "            orient=orient,\n",
    "            var=\"Estimate\",\n",
    "            missing_color='gray',\n",
    "            s=10,\n",
    "            tickangs=(45, 0),\n",
    "            aspect=aspects[orient],\n",
    "            grid=True,\n",
    "            title=f\"Conditional Mean ({var})\",\n",
    "        )\n",
    "        set_axis_label_font(ax)\n",
    "\n",
    "        n_imputed = sum(pd.notna(point_data).apply(lambda x: all(x), axis=1))\n",
    "        if orient == 'xy':\n",
    "            ax.text(0.07, 0.92, f\"n_imputed = {n_imputed:g}\", transform=ax.transAxes)\n",
    "        set_cabr_label_font(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:55:54.199118Z",
     "start_time": "2022-10-12T11:55:52.572619Z"
    }
   },
   "outputs": [],
   "source": [
    "for orient in (\"xy\", \"xz\", \"yz\"):\n",
    "    fig, axes = rmsp.ImageGrid(\n",
    "        1,\n",
    "        len(missing_variables),\n",
    "        figsize=(n_var_miss * 5, 12),\n",
    "        cbar_mode=\"each\",\n",
    "        axes_pad=(0.6, 0.4),\n",
    "    )\n",
    "\n",
    "    for ax, var in zip(axes, missing_variables):\n",
    "\n",
    "        point_data = pd.DataFrame(spatial_dict[var])\n",
    "\n",
    "        point_data = rmsp.PointData(point_data, x=data_ns.x, y=data_ns.y, z=data_ns.z)\n",
    "\n",
    "        point_data.sectionplot(\n",
    "            ax=ax,\n",
    "            orient=orient,\n",
    "            var=\"Variance\",\n",
    "            missing_color='gray',\n",
    "            s=10,\n",
    "            grid=True,\n",
    "            aspect=aspects[orient],\n",
    "            title=f\"Conditional Variance ({var})\",\n",
    "            tickangs=(45, 0),\n",
    "            cmap=\"RdYlGn_r\",\n",
    "        )\n",
    "        set_axis_label_font(ax)\n",
    "\n",
    "        n_imputed = sum(pd.notna(point_data).apply(lambda x: all(x), axis=1))\n",
    "\n",
    "        if ax == 'xy':\n",
    "            ax.text(0.07, 0.92, f\"n_imputed = {n_imputed:g}\", transform=ax.transAxes)\n",
    "            \n",
    "        set_cabr_label_font(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Checking the multivariate relationship (NS units)\n",
    "\n",
    "Relationship between response variables and the imputed ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:55:54.834618Z",
     "start_time": "2022-10-12T11:55:54.200119Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_miss = data_imputation.Missing>0\n",
    "fig = data_imputation[mask_miss].scatplots(\n",
    "    variables=variables, figsize=(10, 10), stats=\"all\", s=8,\n",
    "    lims=(-3.5, 3.5),\n",
    "    num_sample=7000,\n",
    "    axes_pad=(0.15, 0.15),\n",
    "    cmap=cmap,\n",
    "    cbar=True\n",
    ")\n",
    "for ax in fig.axes:\n",
    "    set_axis_label_font(ax, prefix = 'NS:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:55:55.888619Z",
     "start_time": "2022-10-12T11:55:54.835619Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = data_imputation.scatplots(\n",
    "    variables=variables, figsize=(10, 10), stats=\"all\", s=8,\n",
    "    lims=(-3.5, 3.5),\n",
    "    num_sample=7000,\n",
    "    axes_pad=(0.15, 0.15),\n",
    "    cmap=cmap,\n",
    "    cbar=True\n",
    ")\n",
    "for ax in fig.axes:\n",
    "    set_axis_label_font(ax,  prefix = 'NS:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:56:02.227619Z",
     "start_time": "2022-10-12T11:55:55.889619Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = gs.scatter_plots_lu(\n",
    "    data_imputation[mask_miss],\n",
    "    data_imputation,\n",
    "    figsize=(15, 15),\n",
    "    align_orient=False,\n",
    "    lower_variables=['Ni', 'Fe', 'SiO2'],\n",
    "    upper_variables=variables,\n",
    "    stat_blk=\"all\",\n",
    "    s=10,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    set_axis_label_font(ax,  prefix = 'NS:')\n",
    "\n",
    "save_figure_paper(\"LUMV.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:56:04.366118Z",
     "start_time": "2022-10-12T11:56:02.229619Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = scaplot_compare(data_ns, variables, grid=True, s=8,  prefix = 'NS:')\n",
    "fig, axes = scaplot_compare(data_imputation, variables, grid=True, s=8,  prefix = 'NS:')\n",
    "fig, axes = scaplot_compare(data_imputation[mask_miss], variables, grid=True, s=8,  prefix = 'NS:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:56:04.552118Z",
     "start_time": "2022-10-12T11:56:04.367119Z"
    }
   },
   "outputs": [],
   "source": [
    "data_imputation_final = data_imputation.copy()\n",
    "\n",
    "for var in variables:\n",
    "    data_imputation_final[var] = ns_transformers[var].inverse_transform(data_imputation[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:56:05.435119Z",
     "start_time": "2022-10-12T11:56:04.553119Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = create_axes(3,len(variables), (14,4))\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    data_imputation_final.histplot(variable,ax=axes[i], log=True)\n",
    "    set_axis_label_font(axes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location map plot\n",
    "\n",
    "After data imputation, all data locations have a value for the two missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:56:07.992149Z",
     "start_time": "2022-10-12T11:56:05.436118Z"
    }
   },
   "outputs": [],
   "source": [
    "stat = data_imputation_final.describe()\n",
    "for orient in (\"xy\", \"xz\", \"yz\"):\n",
    "    fig, axes = rmsp.ImageGrid(\n",
    "        1,\n",
    "        len(variables),\n",
    "        figsize=(len(variables) * 5, 12),\n",
    "        cbar_mode=\"each\",\n",
    "        axes_pad=(0.6, 0.4),\n",
    "    )\n",
    "    for ax, var in zip(axes, variables):\n",
    "        data_imputation_final.sectionplot(\n",
    "            orient=orient,\n",
    "            var=var,\n",
    "            s=10,\n",
    "            ax=ax,\n",
    "            grid=True,\n",
    "            tickangs=(45, 45),\n",
    "            missing_color=\"r\",\n",
    "            aspect=aspects[orient],\n",
    "        )\n",
    "\n",
    "        set_axis_label_font(ax)\n",
    "        if orient == 'xy':\n",
    "            ax.text(0.1, 0.92, 'n = %d'%(stat[var]['count']), transform=ax.transAxes)\n",
    "        set_cabr_label_font(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:56:13.169118Z",
     "start_time": "2022-10-12T11:56:07.993149Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_miss = data_imputation_final.Missing>0\n",
    "fig,axes = scaplot_compare(data, variables, grid=True, s=8)\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Original (Heterotopic)', y=1.03)\n",
    "save_figure_paper('mv_orig.png')\n",
    "fig,axes = scaplot_compare(data_imputation_final, variables, grid=True, s=8)\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Full (After Imputation)', y=1.03)\n",
    "save_figure_paper('mv_full.png')\n",
    "fig,axes = scaplot_compare(data_imputation_final[mask_miss], variables, grid=True, s=8)\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Imputed locations', y=1.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T02:59:17.948981Z",
     "start_time": "2022-10-15T02:59:17.784481Z"
    }
   },
   "outputs": [],
   "source": [
    "fresh_simulate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T02:59:18.274574Z",
     "start_time": "2022-10-15T02:59:17.999075Z"
    }
   },
   "outputs": [],
   "source": [
    "n_real = 100\n",
    "out_dir_reals = os.path.join(outdir, 'ImputedRealizations')\n",
    "if fresh_simulate:\n",
    "    try:\n",
    "        shutil.rmtree(out_dir_reals)\n",
    "    except:\n",
    "        pass\n",
    "    gs.mkdir(out_dir_reals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T02:59:18.445074Z",
     "start_time": "2022-10-15T02:59:18.276075Z"
    }
   },
   "outputs": [],
   "source": [
    "final_variables = [data_ns.dhid, data_ns.x, data_ns.y, data_ns.z] + variables\n",
    "if fresh_simulate:\n",
    "    simcache = rmsp.SimCache(len(data_ns), file_prefix=outdir+'ImputedRealizations/', variables=final_variables)\n",
    "    simcache.clear()\n",
    "    simcache_final = rmsp.SimCache(len(data_ns), file_prefix=outdir+'ImputedRealizationsFinal/', variables=final_variables)\n",
    "    simcache_final.clear()\n",
    "else:\n",
    "    simcache = rmsp.from_pickle(outdir+'simcache_ns.pkl')\n",
    "    simcache_final = rmsp.from_pickle(outdir+'simcache_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T02:59:18.646574Z",
     "start_time": "2022-10-15T02:59:18.460575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep the null index datafarame\n",
    "data_imputation = data_ns.copy()\n",
    "data_imputation['Missing'] = 0\n",
    "\n",
    "mask = data_imputation[missing_variables].isna().any(axis=1)\n",
    "data_imputation.loc[mask, 'Missing'] = 1\n",
    "\n",
    "data_imputation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T08:52:05.858237Z",
     "start_time": "2022-10-15T02:59:19.017586Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if fresh_simulate:\n",
    "    for ireal in trange(n_real):\n",
    "\n",
    "        data_imputation_real = data_imputation.copy()\n",
    "\n",
    "        for variable in missing_variables:\n",
    "\n",
    "            vario_model = vario_models[variable]\n",
    "#             search = rmsp.Search.from_vario_ranges(vario_model)\n",
    "            search = rmsp.Search([0.0] * 3, [100.0] * 3, min_comps=1, max_comps=100)\n",
    "            krig = rmsp.KrigeEstimator().set_params(\n",
    "                search,\n",
    "                vario_model,\n",
    "                \"sk\",\n",
    "                sk_mean=np.nanmean(data_imputation_real[variable]),\n",
    "            )\n",
    "\n",
    "            # Shuffle data\n",
    "            data_imputation_shuffled = data_imputation_real.sample(frac=1).reset_index(drop=False)\n",
    "\n",
    "            for idx, row in data_imputation_shuffled.iterrows():\n",
    "                \n",
    "                index= row['index']\n",
    "\n",
    "                if pd.isna(row[variable]):\n",
    "\n",
    "                    # mask missing location to implement kriging\n",
    "                    mask = data_imputation_real[\"Hash\"] == row[\"Hash\"]\n",
    "                    result = krig.estimate(\n",
    "                        data_imputation_real.loc[mask],\n",
    "                        data_imputation_real,\n",
    "                        variable,\n",
    "                        output=[\"estimate\", \"estimate_var\"],\n",
    "                    )\n",
    "\n",
    "                    spatial_mean, spatial_variance = (\n",
    "                        result[\"estimate\"].values[0],\n",
    "                        result[\"estimate_var\"].values[0],\n",
    "                    )\n",
    "\n",
    "                    a1, a2, a3, a4 = get_conditional_moments(\n",
    "                        row[response_var_dict[variable]].values.reshape(\n",
    "                            -1, len(response_var_dict[variable])\n",
    "                        ),\n",
    "                        *models_mpl[variable],\n",
    "                        data_ns,\n",
    "                        variable,\n",
    "                    )\n",
    "\n",
    "                    if a2 == 0:\n",
    "                        print(a1, a2, a3, a4)\n",
    "                        # Get the conditioning data for GMM\n",
    "                        conditioning_data = [\n",
    "                            None if math.isnan(val) else val\n",
    "                            for val in row[gmm_util.variable_names]\n",
    "                        ]\n",
    "                        # Get the uni/bivariate conditional distribution based on the GMM components\n",
    "                        (\n",
    "                            cond_means,\n",
    "                            cond_covariances,\n",
    "                            cond_contributions,\n",
    "                        ) = gmm_util.get_conditional_pdf(\n",
    "                            conditioning_data=conditioning_data\n",
    "                        )\n",
    "\n",
    "                        # Grab the marginal univariate GMM componenets (first variable)\n",
    "                        cond_means = np.array(cond_means)\n",
    "                        cond_means = cond_means[:, 0].reshape(gmm_util.n_components, 1)\n",
    "                        cond_covariances = np.array(cond_covariances)\n",
    "                        cond_covariances = cond_covariances[:, 0, 0].reshape(\n",
    "                            gmm_util.n_components, 1, 1\n",
    "                        )\n",
    "                        a1, a2, a3, a4 = gmm_util.get_moments(\n",
    "                            cond_means, cond_covariances, cond_contributions\n",
    "                        )\n",
    "\n",
    "                    # Fit the lambda distribution given the first four moments\n",
    "                    lambdas = get_lambdas_keras(a1, a2, a3, a4, mlp_model)\n",
    "\n",
    "                    gld = GeneralizedLambdaDist(*lambdas)\n",
    "\n",
    "                    x_vals, F_gld, F_spatial, F_global, F_updated = update_bayesian_pr(\n",
    "                        gld,\n",
    "                        spatial_mean=spatial_mean,\n",
    "                        spatial_variance=spatial_variance,\n",
    "                    )\n",
    "\n",
    "                    sim_val = simulate(F_updated, x_vals)\n",
    "                    if np.isnan(sim_val):\n",
    "                        print(\n",
    "                            variable,\n",
    "                            index,\n",
    "                            a1,\n",
    "                            a2,\n",
    "                            a3,\n",
    "                            a4,\n",
    "                            *lambdas,\n",
    "                            spatial_mean,\n",
    "                            spatial_variance,\n",
    "                        )\n",
    "\n",
    "                    data_imputation_real.loc[index, variable] = sim_val\n",
    "\n",
    "        simcache.set_real(ireal, data_imputation_real[final_variables])\n",
    "\n",
    "        # back transformation\n",
    "        data_imputation_real_final = data_imputation_real.copy()\n",
    "        for var in variables:\n",
    "            data_imputation_real_final[var] = ns_transformers[var].inverse_transform(\n",
    "                data_imputation_real[var]\n",
    "            )\n",
    "\n",
    "        simcache_final.set_real(ireal, data_imputation_real_final[final_variables])\n",
    "\n",
    "        del(data_imputation_real_final); del(data_imputation_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:40:09.767549Z",
     "start_time": "2022-10-22T03:40:09.571049Z"
    }
   },
   "outputs": [],
   "source": [
    "data_all = rmsp.from_pickle(data_dir+'AllData.pkl')\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:40:11.625125Z",
     "start_time": "2022-10-22T03:40:10.403128Z"
    }
   },
   "outputs": [],
   "source": [
    "psims_final = {}\n",
    "for var in missing_variables:\n",
    "    psims_final[var] = rmsp.postsim(simcache_final, var=var)\n",
    "    psims_final[var][f'{var} True'] = data_all[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T03:22:00.096839Z",
     "start_time": "2022-10-16T03:21:58.910839Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = create_axes(len(missing_variables), len(missing_variables), (9, 4))\n",
    "for (var, psim), ax in zip(psims_final.items(), axes):\n",
    "    mask = psim[f\"{var} stdev\"] > 0.0\n",
    "    cv = rmsp.CrossVal(psim[mask], var + \" e-type\", f\"{var} True\")\n",
    "    cv.scatplot(\n",
    "        psim[mask],\n",
    "        ax=ax,\n",
    "        s=4,\n",
    "        c=\"#838383\",\n",
    "        plot_worst=False,\n",
    "        grid=True,\n",
    "        stats=[\"count\", \"meanx\", \"meany\", \"rmse\", \"corr\", \"sor\"],\n",
    "    )\n",
    "    set_axis_label_font(ax)\n",
    "fig.tight_layout()\n",
    "save_figure_paper(\"cv_dp_ld_etype.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T03:22:27.526426Z",
     "start_time": "2022-10-16T03:22:26.263427Z"
    }
   },
   "outputs": [],
   "source": [
    "real = simcache_final.get_real(0)\n",
    "for var in missing_variables:\n",
    "    real[f\"{var} True\"] = data_all[var]\n",
    "fig, axes = create_axes(len(missing_variables), len(missing_variables), (9, 4))\n",
    "for (var, psim), ax in zip(psims_final.items(), axes):\n",
    "    mask = psim[f\"{var} stdev\"] > 0.0\n",
    "    cv = rmsp.CrossVal(real[mask], var, f\"{var} True\")\n",
    "    cv.scatplot(\n",
    "        real[mask],\n",
    "        ax=ax,\n",
    "        s=4,\n",
    "        c=\"#838383\",\n",
    "        plot_worst=False,\n",
    "        grid=True,\n",
    "        stats=[\"count\", \"meanx\", \"meany\", \"rmse\", \"corr\", \"sor\"],\n",
    "    )\n",
    "    set_axis_label_font(ax)\n",
    "fig.tight_layout()\n",
    "save_figure_paper(\"cv_dp_ld_real.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realization stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T13:11:40.195513Z",
     "start_time": "2022-10-14T13:11:37.922327Z"
    }
   },
   "outputs": [],
   "source": [
    "real_list = {var: [] for var in missing_variables}\n",
    "mask_dict = {var: psims_final[var][f'{var} stdev']>0.0 for var in missing_variables}\n",
    "\n",
    "for ireal, real in simcache_final.iter_realizations():\n",
    "    for var in missing_variables:\n",
    "        real_list[var].append(real[mask_dict[var]][var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:19:22.160043Z",
     "start_time": "2022-10-12T18:19:21.541546Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = create_axes(len(missing_variables), len(missing_variables), (14,6))\n",
    "for var, ax in zip(missing_variables, axes):\n",
    "    real_data = pd.concat(real_list[var], axis=1)\n",
    "\n",
    "    indices = real_data.index\n",
    "\n",
    "    unistats = []\n",
    "    names = []\n",
    "    true_values = []\n",
    "    count = 1\n",
    "    for i, idx in enumerate(indices[0:10]):\n",
    "        unistats.append(rmsp.UniStats(real_data.loc[idx].values))\n",
    "        names.append(f'Loc {i+1}')\n",
    "        true_values.append(data_all.loc[idx, var])\n",
    "\n",
    "    unicompare = rmsp.UniCompare(unistats, names = names, setname='Missing Locations')\n",
    "    unicompare.boxplot(ax=ax)\n",
    "    ax.set_ylabel(var)\n",
    "    set_axis_label_font(ax)\n",
    "\n",
    "    width = (np.diff(ax.get_xticks())).mean() / 2\n",
    "    for val, tick in zip(true_values, ax.get_xticks()):\n",
    "        ax.hlines(val, tick-width, tick+width, color='r', ls='--')\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Reproduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:19:23.632543Z",
     "start_time": "2022-10-12T18:19:22.161044Z"
    }
   },
   "outputs": [],
   "source": [
    "ref_unistats = {}\n",
    "sim_unistats = {}\n",
    "for var in variables:\n",
    "    ref_unistats[var] = rmsp.UniStats(\n",
    "        data_ns[var]\n",
    "    )\n",
    "    sim_unistats[var] = [\n",
    "        rmsp.UniStats(simcache.get_real(ireal, var)[var])\n",
    "        for ireal in range(n_real)\n",
    "    ]\n",
    "fig, axes = create_axes(3,len(variables), (14,4))\n",
    "\n",
    "for var, ax in zip(variables, axes):\n",
    "    ref_unistats[var].cdfplot_checkreals(sim_unistats[var], ax=ax)\n",
    "    set_axis_label_font(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:40:38.678259Z",
     "start_time": "2022-10-22T03:40:36.452260Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ref_unistats = {}\n",
    "sim_unistats = {}\n",
    "for var in variables:\n",
    "    ref_unistats[var] = rmsp.UniStats(\n",
    "        data[var], data[f'{var}_wt']\n",
    "    )\n",
    "    sim_unistats[var] = [\n",
    "        rmsp.UniStats(simcache_final.get_real(ireal, var)[var])\n",
    "        for ireal in range(n_real)\n",
    "    ]\n",
    "fig, axes = create_axes(3,len(variables), (14,4))\n",
    "for var, ax in zip(variables, axes):\n",
    "    ref_unistats[var].cdfplot_checkreals(\n",
    "        sim_unistats[var], ax=ax, log=False, grid=True,\n",
    "    )\n",
    "    set_axis_label_font(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T03:40:52.617355Z",
     "start_time": "2022-10-22T03:40:51.052854Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(missing_variables), figsize=(12, 4))\n",
    "\n",
    "for var, ax in zip(missing_variables, axes):\n",
    "    ref_unistats[var].cdfplot_checkreals(\n",
    "        sim_unistats[var], ax=ax, log=False, grid=True, stats=[\"mean\", \"count\"]\n",
    "    )\n",
    "    set_axis_label_font(ax)\n",
    "save_figure_paper(\"hist_repro.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variogram reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:19:30.095866Z",
     "start_time": "2022-10-12T18:19:27.183368Z"
    }
   },
   "outputs": [],
   "source": [
    "vario_exp_orig = {}\n",
    "for var in missing_variables:\n",
    "    vario_exp_orig[var] = rmsp.ExpVario(\"backns\").calculate(\n",
    "        data, var, searches=exp_vario_search, nstransformer = ns_transformers[var]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:24:01.881154Z",
     "start_time": "2022-10-12T18:19:30.096868Z"
    }
   },
   "outputs": [],
   "source": [
    "vario_exp_reals = []\n",
    "for ireal, real in simcache_final.iter_realizations():\n",
    "    vario_exp_real = {}\n",
    "    real = rmsp.PointData(real, x=data.x, y=data.y, z=data.z)\n",
    "    for var in missing_variables:\n",
    "        vario_exp_real[var] = rmsp.ExpVario(\"backns\").calculate(\n",
    "            real, var, searches=exp_vario_search, nstransformer = ns_transformers[var]\n",
    "        )\n",
    "        \n",
    "    vario_exp_reals.append(vario_exp_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:25.734104Z",
     "start_time": "2022-10-12T18:24:01.882152Z"
    }
   },
   "outputs": [],
   "source": [
    "vario_exp_reals_ns = []\n",
    "for ireal, real in simcache.iter_realizations():\n",
    "    vario_exp_real_ns = {}\n",
    "    real = rmsp.PointData(real, x=data.x, y=data.y, z=data.z)\n",
    "    for var in missing_variables:\n",
    "        vario_exp_real_ns[var] = rmsp.ExpVario(\"traditional\").calculate(\n",
    "            real, var, searches=exp_vario_search\n",
    "        )\n",
    "        \n",
    "    vario_exp_reals_ns.append(vario_exp_real_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:32.399103Z",
     "start_time": "2022-10-12T18:27:25.735604Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "        \n",
    "for vario_calc in vario_exp_reals:\n",
    "    for i, var in enumerate(missing_variables):\n",
    "        data_var = vario_calc[var].data\n",
    "        for index in data_var['Search Index'].unique():\n",
    "            mask = data_var['Search Index'] == index\n",
    "            vario_calc[var].plot_draw(\n",
    "                search_index=index,\n",
    "                ax=axes[int(index), i],\n",
    "                c='gray',\n",
    "                ls='-',\n",
    "                lw=2\n",
    "            )\n",
    "            \n",
    "for i, var in enumerate(missing_variables):\n",
    "    data_var = vario_exp_orig[var].data\n",
    "    for index in data_var['Search Index'].unique():\n",
    "        mask = data_var['Search Index'] == index\n",
    "        azim = data_var[mask].Azimuth.mean()\n",
    "        incl = data_var[mask].Inclination.mean()\n",
    "        vario_exp_orig[var].plot(\n",
    "            search_index=index,\n",
    "            ax=axes[int(index), i],\n",
    "            ylim=(0, 1.5),\n",
    "            title=(f\"{var} (azim: {azim:.1f}, incl: {incl:.1f})\"),\n",
    "            c=f'C{i}',\n",
    "            ls='--',\n",
    "            ms=5,\n",
    "            tickangs = (45,0),\n",
    "            lw=0.5,\n",
    "            grid=True\n",
    "        )\n",
    "        \n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=12)\n",
    "    ax.set_title(ax.get_title(), fontsize=12)\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure_paper('vario_repro.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:38.909101Z",
     "start_time": "2022-10-12T18:27:32.400103Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "        \n",
    "for vario_calc in vario_exp_reals_ns:\n",
    "    for i, var in enumerate(missing_variables):\n",
    "        data_var = vario_calc[var].data\n",
    "        for index in data_var['Search Index'].unique():\n",
    "            mask = data_var['Search Index'] == index\n",
    "            vario_calc[var].plot_draw(\n",
    "                search_index=index,\n",
    "                ax=axes[int(index), i],\n",
    "                c='gray',\n",
    "                ls='-',\n",
    "                lw=2\n",
    "            )\n",
    "            \n",
    "for i, var in enumerate(missing_variables):\n",
    "    data_var = vario_exp[var].data\n",
    "    for index in data_var['Search Index'].unique():\n",
    "        mask = data_var['Search Index'] == index\n",
    "        azim = data_var[mask].Azimuth.mean()\n",
    "        incl = data_var[mask].Inclination.mean()\n",
    "        vario_exp[var].plot(\n",
    "            search_index=index,\n",
    "            ax=axes[int(index), i],\n",
    "            ylim=(0, 1.5),\n",
    "            title=(f\"{var} (azim: {azim:.1f}, incl: {incl:.1f})\"),\n",
    "            c=f'C{i}',\n",
    "            ls='--',\n",
    "            ms=5,\n",
    "            tickangs = (45,0),\n",
    "            lw=0.5,\n",
    "            grid=True\n",
    "        )\n",
    "#         vario_models[var].plot_draw(\n",
    "#             ax=axes[int(index), i], azm=azim, incl=0.0, lw=2, c=\"k\", ls=\"--\"\n",
    "#         )\n",
    "        \n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=12)\n",
    "    ax.set_title(ax.get_title(), fontsize=12)\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure_paper('vario_repro_ns.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix Reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:41.993100Z",
     "start_time": "2022-10-12T18:27:38.910101Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bivstat(ireal):\n",
    "    sim = simcache_final.get_real(\n",
    "        ireal, columns=variables\n",
    "    )\n",
    "    return rmsp.BivStats(\n",
    "        sim, variables\n",
    "    )\n",
    "\n",
    "\n",
    "parallel_args = [ireal for ireal in range(n_real)]\n",
    "all_biv_stats = rmsp.parallel_runner(\n",
    "    get_bivstat,\n",
    "    parallel_args,\n",
    "    num_threads=rmsp.GlobalParams[\"core.num_threads\"],\n",
    "    progressbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:42.163600Z",
     "start_time": "2022-10-12T18:27:41.994101Z"
    }
   },
   "outputs": [],
   "source": [
    "ref_bivstat = rmsp.BivStats(\n",
    "    data,\n",
    "    variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:43.403600Z",
     "start_time": "2022-10-12T18:27:42.164601Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = ref_bivstat.matrixplot_checkreals(all_biv_stats, figsize=(10, 10), stat=\"rankcorr\")\n",
    "save_figure_paper('corr_matrix_original.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:43.589579Z",
     "start_time": "2022-10-12T18:27:43.404601Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_data(simcache, 'simcache_ns.pkl')\n",
    "pickle_data(simcache_final, 'simcache_final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style='color:#1B127A;'> RMSP GMM </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#5177F9;'> Imputation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:43.760047Z",
     "start_time": "2022-10-12T18:27:43.590569Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer = rmsp.GMMImputer().fit(data_ns, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:45.000048Z",
     "start_time": "2022-10-12T18:27:43.761049Z"
    }
   },
   "outputs": [],
   "source": [
    "search = rmsp.Search([0.0] * 3, [100.0] * 3, min_comps=1, max_comps=100)\n",
    "num_search = 20\n",
    "\n",
    "variomod_dict = {}\n",
    "for var in vario_models:\n",
    "    variomod_dict[var] = vario_models[var]\n",
    "for var in response_variables:\n",
    "    # a dummy model since the first variable has no missing samples\n",
    "    vario_dict = dict(\n",
    "        num_struct=1,\n",
    "        nugget=0.05,\n",
    "        shapes=[\"spherical\"],\n",
    "        var_contribs=[0.95],\n",
    "        angles=[0.0] * 3,\n",
    "        ranges=[100] * 3,\n",
    "    )\n",
    "    variomod_dict[var] = rmsp.VarioModel(vario_dict)\n",
    "\n",
    "rmsp_nscache = imputer.impute(\n",
    "    variomod_dict,\n",
    "    gmm_model,\n",
    "    search,\n",
    "    num_search,\n",
    "    reals=n_real,\n",
    "    cache=outdir + \"rmsp_cache_ns\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:47.339326Z",
     "start_time": "2022-10-12T18:27:45.001049Z"
    }
   },
   "outputs": [],
   "source": [
    "rmsp_finalcache = rmsp.SimCache(len(data_ns), file_prefix=outdir + \"rmsp_cache_final\",)\n",
    "for ireal, real in rmsp_nscache.iter_realizations():\n",
    "    real_final = data_ns[[]].copy()\n",
    "    for var in variables:\n",
    "        real_final[var] = ns_transformers[var].inverse_transform(\n",
    "            real[var]\n",
    "        )\n",
    "\n",
    "    rmsp_finalcache.set_real(ireal, real_final[variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#5177F9;'> Checks </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:48.315558Z",
     "start_time": "2022-10-12T18:27:47.340326Z"
    }
   },
   "outputs": [],
   "source": [
    "psims_final_rms = {}\n",
    "for var in missing_variables:\n",
    "    psims_final_rms[var] = rmsp.postsim(rmsp_finalcache, var=var)\n",
    "    psims_final_rms[var][f'{var} True'] = data_all[var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#51AFF9;'> Cross validations </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T03:22:42.235589Z",
     "start_time": "2022-10-16T03:22:41.056088Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = create_axes(len(missing_variables), len(missing_variables), (9, 4))\n",
    "for (var, psim), ax in zip(psims_final_rms.items(), axes):\n",
    "    mask = psim[f\"{var} stdev\"] > 0.0\n",
    "    cv = rmsp.CrossVal(psim[mask], var + \" e-type\", f\"{var} True\")\n",
    "    cv.scatplot(\n",
    "        psim[mask],\n",
    "        ax=ax,\n",
    "        s=4,\n",
    "        c=\"#838383\",\n",
    "        plot_worst=False,\n",
    "        grid=True,\n",
    "        stats=[\"count\", \"meanx\", \"meany\", \"rmse\", \"corr\", \"sor\"],\n",
    "    )\n",
    "    set_axis_label_font(ax)\n",
    "fig.tight_layout()\n",
    "save_figure_paper(\"cv_gmm_etype.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T03:22:58.018211Z",
     "start_time": "2022-10-16T03:22:56.816209Z"
    }
   },
   "outputs": [],
   "source": [
    "real_rms = rmsp_finalcache.get_real(0)\n",
    "for var in missing_variables:\n",
    "    real_rms[f\"{var} True\"] = data_all[var]\n",
    "fig, axes = create_axes(len(missing_variables), len(missing_variables), (9, 4))\n",
    "for (var, psim), ax in zip(psims_final_rms.items(), axes):\n",
    "    mask = psim[f\"{var} stdev\"] > 0.0\n",
    "    cv = rmsp.CrossVal(real_rms[mask], var, f\"{var} True\")\n",
    "    cv.scatplot(\n",
    "        real_rms[mask],\n",
    "        ax=ax,\n",
    "        s=4,\n",
    "        c=\"#838383\",\n",
    "        plot_worst=False,\n",
    "        grid=True,\n",
    "        stats=[\"count\", \"meanx\", \"meany\", \"rmse\", \"corr\", \"sor\"],\n",
    "    )\n",
    "    set_axis_label_font(ax)\n",
    "fig.tight_layout()\n",
    "save_figure_paper(\"cv_gmm_real.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:49.942634Z",
     "start_time": "2022-10-12T18:27:48.906559Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,axes = scaplot_compare(rmsp_finalcache.get_real(0), variables, grid=True, s=8)\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Imputed locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#51AFF9;'> NS Histogram Checks </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:51.415058Z",
     "start_time": "2022-10-12T18:27:49.944059Z"
    }
   },
   "outputs": [],
   "source": [
    "ref_unistats = {}\n",
    "sim_unistats_rms = {}\n",
    "for var in variables:\n",
    "    ref_unistats[var] = rmsp.UniStats(\n",
    "        data_ns[var]\n",
    "    )\n",
    "    sim_unistats_rms[var] = [\n",
    "        rmsp.UniStats(rmsp_nscache.get_real(ireal, var)[var])\n",
    "        for ireal in range(n_real)\n",
    "    ]\n",
    "    \n",
    "fig, axes = create_axes(3,len(variables), (14,4))\n",
    "\n",
    "for var, ax in zip(variables, axes):\n",
    "    ref_unistats[var].cdfplot_checkreals(sim_unistats_rms[var], ax=ax)\n",
    "    set_axis_label_font(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#51AFF9;'> Original histogram checks </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:27:55.290058Z",
     "start_time": "2022-10-12T18:27:51.416058Z"
    }
   },
   "outputs": [],
   "source": [
    "ref_unistats = {}\n",
    "sim_unistats_rms = {}\n",
    "for var in variables:\n",
    "    ref_unistats[var] = rmsp.UniStats(\n",
    "        data[var], data[f'{var}_wt']\n",
    "    )\n",
    "    sim_unistats_rms[var] = [\n",
    "        rmsp.UniStats(rmsp_finalcache.get_real(ireal, var)[var])\n",
    "        for ireal in range(n_real)\n",
    "    ]\n",
    "fig, axes = create_axes(3,len(variables), (14,4))\n",
    "for var, ax in zip(variables, axes):\n",
    "    ref_unistats[var].cdfplot_checkreals(\n",
    "        sim_unistats_rms[var], ax=ax, log=True, grid=True,\n",
    "    )\n",
    "    set_axis_label_font(ax)\n",
    "    \n",
    "fig, axes = plt.subplots(1, len(missing_variables), figsize=(12, 4))\n",
    "\n",
    "for var, ax in zip(missing_variables, axes):\n",
    "    ref_unistats[var].cdfplot_checkreals(\n",
    "        sim_unistats[var], ax=ax, log=True, grid=True, stats=[\"mean\", \"count\"]\n",
    "    )\n",
    "    set_axis_label_font(ax)\n",
    "save_figure_paper(\"hist_repro_rmsp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#51AFF9;'> Variogram Reproduction </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:32:27.046596Z",
     "start_time": "2022-10-12T18:27:55.291060Z"
    }
   },
   "outputs": [],
   "source": [
    "vario_exp_reals = []\n",
    "for ireal, real in rmsp_finalcache.iter_realizations(points=data):\n",
    "    vario_exp_real = {}\n",
    "    real = rmsp.PointData(real, x=data.x, y=data.y, z=data.z)\n",
    "    for var in missing_variables:\n",
    "        vario_exp_real[var] = rmsp.ExpVario(\"backns\").calculate(\n",
    "            real, var, searches=exp_vario_search, nstransformer = ns_transformers[var]\n",
    "        )\n",
    "        \n",
    "    vario_exp_reals.append(vario_exp_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:32:33.509131Z",
     "start_time": "2022-10-12T18:32:27.047598Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "        \n",
    "for vario_calc in vario_exp_reals:\n",
    "    for i, var in enumerate(missing_variables):\n",
    "        data_var = vario_calc[var].data\n",
    "        for index in data_var['Search Index'].unique():\n",
    "            mask = data_var['Search Index'] == index\n",
    "            vario_calc[var].plot_draw(\n",
    "                search_index=index,\n",
    "                ax=axes[int(index), i],\n",
    "                c='gray',\n",
    "                ls='-',\n",
    "                lw=2\n",
    "            )\n",
    "            \n",
    "for i, var in enumerate(missing_variables):\n",
    "    data_var = vario_exp_orig[var].data\n",
    "    for index in data_var['Search Index'].unique():\n",
    "        mask = data_var['Search Index'] == index\n",
    "        azim = data_var[mask].Azimuth.mean()\n",
    "        incl = data_var[mask].Inclination.mean()\n",
    "        vario_exp_orig[var].plot(\n",
    "            search_index=index,\n",
    "            ax=axes[int(index), i],\n",
    "            ylim=(0, 1.5),\n",
    "            title=(f\"{var} (azim: {azim:.1f}, incl: {incl:.1f})\"),\n",
    "            c=f'C{i}',\n",
    "            ls='--',\n",
    "            ms=5,\n",
    "            tickangs = (45,0),\n",
    "            lw=0.5,\n",
    "            grid=True\n",
    "        )\n",
    "        \n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=12)\n",
    "    ax.set_title(ax.get_title(), fontsize=12)\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure_paper('vario_repro_rmsp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:32:33.695097Z",
     "start_time": "2022-10-12T18:32:33.510098Z"
    }
   },
   "outputs": [],
   "source": [
    "# gs.rmdir(outdir) #command to delete generated data file\n",
    "# gs.rmfile('temp') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "857.6px",
    "left": "163px",
    "top": "110px",
    "width": "293.466px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
